{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 2: Linear Models and Validation Metrics (30 marks total)\n",
    "### Due: October 10 at 11:59pm\n",
    "\n",
    "### Name: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 1: Classification (14.5 marks total)\n",
    "\n",
    "You have been asked to develop code that can help the user determine if the email they have received is spam or not. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3c6fc8",
   "metadata": {},
   "source": [
    "### Step 0: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33f86925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/spam.html\n",
    "\n",
    "Use the yellowbrick function `load_spam()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X: 262200 and y: 4600\n",
      "Type of X: <class 'pandas.core.frame.DataFrame'>\n",
      "Type of y: <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library\n",
    "# TO DO: Print size and type of X and y\n",
    "from yellowbrick.datasets import load_spam\n",
    "X, y = load_spam()\n",
    "\n",
    "# TO DO: Print size and type of X and y\n",
    "print(f\"Size of X: {X.size} and y: {y.size}\\nType of X: {type(X)}\\nType of y: {type(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1.5 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e7204f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "if X.isna().sum().sum():\n",
    "    print(\"X contains nan values\")\n",
    "    X.fillna(0, inplace=True) # this step was not neccesary but I added it to practice\n",
    "    \n",
    "if(y.isna().any()):\n",
    "    print(\"y contains nan values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489285a",
   "metadata": {},
   "source": [
    "For this task, we want to test if the linear model would still work if we used less data. Use the `train_test_split` function from sklearn to create a new feature matrix named `X_small` and a new target vector named `y_small` that contain **5%** of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9bc4a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Create X_small and y_small \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 95% of the data is ignored and only 5% is kept \n",
    "X_small, _, y_small, _ = train_test_split(X, y, test_size=0.95, random_state=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `LogisticRegression` from sklearn\n",
    "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
    "3. Implement the machine learning model with three different datasets: \n",
    "    - `X` and `y`\n",
    "    - Only first two columns of `X` and `y`\n",
    "    - `X_small` and `y_small`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2a4cb5f-36af-48a7-8756-1ed391171949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import copy\n",
    "\n",
    "logreg = LogisticRegression(max_iter=2000)\n",
    "model = []\n",
    "\n",
    "# Implementing X and y using the standard split (80% data for training and 20% for testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)  \n",
    "model.append(copy.deepcopy(logreg).fit(X_train, y_train)) \n",
    "\n",
    "# Implementing only first two colums of X and y\n",
    "X_subset = X.iloc[:, :2]  # Selecting only the first two columns of X\n",
    "X_subset_train, X_subset_test, y_subset_train, y_subset_test = train_test_split(X_subset, y, test_size=0.2, random_state=0)\n",
    "model.append(copy.deepcopy(logreg).fit(X_subset_train, y_subset_train))\n",
    "\n",
    "# Implementing X_small and y_small\n",
    "X_small_train, X_small_test, y_small_train, y_small_test = train_test_split(X_small, y_small, test_size=0.2, random_state=0)\n",
    "model.append(copy.deepcopy(logreg).fit(X_small, y_small))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89f3d84",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the training and validation accuracy for the three different tests implemented in Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47acf8fd-367c-4fd0-9237-83d8f77373a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "training_accuracy = []\n",
    "validation_accuracy = []\n",
    "\n",
    "# Validate model 1\n",
    "y_train_pred = model[0].predict(X_train)\n",
    "training_accuracy.append(accuracy_score(y_train, y_train_pred))\n",
    "y_val_pred = model[0].predict(X_test)\n",
    "validation_accuracy.append(accuracy_score(y_test, y_val_pred))\n",
    "\n",
    "# Validate model 2\n",
    "y_train_pred = model[1].predict(X_subset_train)\n",
    "training_accuracy.append(accuracy_score(y_subset_train, y_train_pred))\n",
    "y_val_pred = model[1].predict(X_subset_test)\n",
    "validation_accuracy.append(accuracy_score(y_subset_test, y_val_pred))\n",
    "\n",
    "# Validate model 3\n",
    "y_train_pred = model[2].predict(X_small_train)\n",
    "training_accuracy.append(accuracy_score(y_small_train, y_train_pred))\n",
    "y_val_pred = model[2].predict(X_small_test)\n",
    "validation_accuracy.append(accuracy_score(y_small_test, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352106a3",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Data size  Training accuracy  Validation accuracy\n",
      "X and y               209760           0.927174             0.938043\n",
      "First two columns       7360           0.614946             0.593478\n",
      "5% of data             13110           0.945652             0.956522\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Data size': [X_train.size, X_subset_train.size, X_small.size],\n",
    "    'Training accuracy': [*training_accuracy],\n",
    "    'Validation accuracy': [*validation_accuracy]\n",
    "}, index = ['X and y', 'First two columns', '5% of data'])\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4427d4f",
   "metadata": {},
   "source": [
    "### Questions (4 marks)\n",
    "1. How do the training and validation accuracy change depending on the amount of data used? Explain with values.\n",
    "2. In this case, what do a false positive and a false negative represent? Which one is worse?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1366da0-d8ac-4956-b08d-da2cc2f11578",
   "metadata": {},
   "source": [
    "Answers:\n",
    "1. They change based on the amount of samples and the amount of features. In general having more samples improves the model and the accuracy but sometimes small subsets can capture the pattern well enough. That was the case while using only 5% of the data for this exercise. Fitting the model with only two features performed poorly because the model only yielded correct prediction 60% of time meaning the model may be overfitted.\n",
    "2. False positive is an e-email that was classified as spam by the model but in reality it is not. On the other hand false negative is an e-mail classified as not spam by the model but in reality it is spam. For a real life scenario a false positive is worse because you can miss a very important email if it sent to a spam folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7559517a",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe687f",
   "metadata": {},
   "source": [
    "I completed all the steps in this assignment in the order they appeared.\n",
    "\n",
    "I sourced my code mainly from the Binary Classification-filled and Linear Classification-filled notebooks from D2L and some help from ChatGPT. For example I wrote \"I have a dataframe df, how do I obtain the first columns only?\" and it suggested me to use first_two_columns = df[:, :2] but it didn't work. Then I looked at the notebooks from ENSF 592 and realized I needed to use .iloc so I made that modification myself. \n",
    "\n",
    "Did you have any challenges? If yes, what were they? If not, what helped you to be successful? I don't consider I countered any big challenges in terms of coding but I had some problems understanding the confusion matrix, recall, Precision-Recall curves etc so I watched a bunch of youtube videos specifically from StatQuest, and they were helpful. I like that I can go back an rewatch them as many times as needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4c78a8",
   "metadata": {},
   "source": [
    "## Part 2: Regression (10.5 marks total)\n",
    "\n",
    "For this section, we will be evaluating concrete compressive strength of different concrete samples, based on age and ingredients. You will need to repeat the steps 1-4 from Part 1 for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ba83c5",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ff2e34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X: 8240 and y: 1030\n",
      "Type of X: <class 'pandas.core.frame.DataFrame'>\n",
      "Type of y: <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library\n",
    "# TO DO: Print size and type of X and y\n",
    "from yellowbrick.datasets import load_concrete\n",
    "X, y = load_concrete()\n",
    "\n",
    "print(f\"Size of X: {X.size} and y: {y.size}\\nType of X: {type(X)}\\nType of y: {type(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5294cfa",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0.5 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "693c5fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "if X.isna().any().any():\n",
    "    print(\"X contains nan values\")\n",
    "    \n",
    "if y.isna().any():\n",
    "    print(\"X contains nan values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc60489",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model (1 mark)\n",
    "\n",
    "1. Import `LinearRegression` from sklearn\n",
    "2. Instantiate model `LinearRegression()`.\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5041945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "linear = LinearRegression().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de28482",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model (1 mark)\n",
    "\n",
    "Calculate the training and validation accuracy using mean squared error and R2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "970c038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "y_train_pred = linear.predict(X_train)\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "y_val_pred = linear.predict(X_test)\n",
    "mse_val = mean_squared_error(y_test, y_val_pred)\n",
    "r2_val = linear.score(X_test, y_test) # the score method also calculates the R2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aa7795",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (1 mark)\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: MSE and R2 score\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88d223f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training accuracy</th>\n",
       "      <th>Validation accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>110.345501</td>\n",
       "      <td>95.635335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>0.609071</td>\n",
       "      <td>0.636898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Training accuracy  Validation accuracy\n",
       "MSE         110.345501            95.635335\n",
       "R2            0.609071             0.636898"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "results = pd.DataFrame({\n",
    "    \"Training accuracy\": [mse_train, r2_train],\n",
    "    \"Validation accuracy\": [mse_val, r2_val]\n",
    "    }, index = [\"MSE\", \"R2\"], )\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a42bda",
   "metadata": {},
   "source": [
    "### Questions (2 marks)\n",
    "1. Did using a linear model produce good results for this dataset? Why or why not?\n",
    "\n",
    "A linear model for this specific dataset is not the best approach. This is due because the concrete compressive strength is a highly nonlinear function of age and ingredients as described in the yellowbrick's concrete dataset website. This means that a straight line is unable to capture the complexity of the patterns accurately, the resulting model is highly biased and underfit. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca0ff2f",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdb0880",
   "metadata": {},
   "source": [
    "I sourced my code from the Linear Regresion and Regression Metrics notebooks from D2L. And I completed the steps in the order they were presented. Altough not required I printed the X features and look up at the concrete yellowbrick website to understand the data at hand.\n",
    "\n",
    "I did not used any generative AI for this exercise as they were not neccesary. But I did watch R2 cofficient of determination from the StatQuest channel on youtube. \n",
    "\n",
    "Again there were no big challenges code related. Although the R2 scores I observed where not as good as I expected and because of that I reviewed my code several times to make sure the low R2 values were not due to a coding mistake."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ac3eb",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "One pattern I observed that is not very usual is that the R2 validation accuracy 0.636898 is slightly better than the R2 for the training accuracy 0.609071 meaning that the model is generalizing \"well\" (although the R2 is still poor for both) when it sees new data. This is also observed when comparing the mse training accuracy 110.34 vs the mse validation accuracy 95.63 indicating once again that the error or distance from the line the predictions of new values is minor than of the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b84eed",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "Something that I am finding challenging is to follow along the lab sessions because they feel a little rushed and sometimes the microphone is dead so I don't hear the explanations and it makes it confusing for the assigments. But I like that we have several examples on D2L to guide us trough the process of implementing and validating the machine learning models we study. I found machine learning interesting overall and I think we will see a huge increase in the implementation of this algorithms in the real world."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db951b3a",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (4 marks)\n",
    "\n",
    "Repeat Part 2 with Ridge and Lasso regression to see if you can improve the accuracy results. Which method and what value of alpha gave you the best R^2 score? Is this score \"good enough\"? Explain why or why not.\n",
    "\n",
    "**Remember**: Only test values of alpha from 0.001 to 100 along the logorithmic scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5f34580-e329-4526-9ec1-93588c09932f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training score</th>\n",
       "      <th>Validation score</th>\n",
       "      <th>Number of features</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alpha Values</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.609071</td>\n",
       "      <td>0.636898</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.609071</td>\n",
       "      <td>0.636898</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0100</th>\n",
       "      <td>0.609071</td>\n",
       "      <td>0.636898</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>0.609071</td>\n",
       "      <td>0.636898</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>0.609071</td>\n",
       "      <td>0.636899</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0000</th>\n",
       "      <td>0.609071</td>\n",
       "      <td>0.636902</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.0000</th>\n",
       "      <td>0.609071</td>\n",
       "      <td>0.636937</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Training score  Validation score  Number of features\n",
       "Alpha Values                                                      \n",
       "0.0001              0.609071          0.636898                 8.0\n",
       "0.0010              0.609071          0.636898                 8.0\n",
       "0.0100              0.609071          0.636898                 8.0\n",
       "0.1000              0.609071          0.636898                 8.0\n",
       "1.0000              0.609071          0.636899                 8.0\n",
       "10.0000             0.609071          0.636902                 8.0\n",
       "100.0000            0.609071          0.636937                 8.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "alpha = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "df = pd.DataFrame(columns = alpha, \n",
    "    index = ['Training score', 'Validation score', 'Number of features'])\n",
    "df.columns.name = 'Alpha Values'\n",
    "\n",
    "for a in alpha:\n",
    "    ridge = Ridge(alpha=a).fit(X_train, y_train) \n",
    "    df[a] = [ridge.score(X_train, y_train), ridge.score(X_test, y_test), \n",
    "             np.sum(ridge.coef_ != 0)]\n",
    "\n",
    "df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d5a134b-d21d-46c8-b9b1-d500b785ee1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training score</th>\n",
       "      <th>Validation score</th>\n",
       "      <th>Number of features</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alpha Values</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.609071</td>\n",
       "      <td>0.636898</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.609071</td>\n",
       "      <td>0.636899</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0100</th>\n",
       "      <td>0.609071</td>\n",
       "      <td>0.636912</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>0.609069</td>\n",
       "      <td>0.637034</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>0.608852</td>\n",
       "      <td>0.638035</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0000</th>\n",
       "      <td>0.602880</td>\n",
       "      <td>0.638874</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.0000</th>\n",
       "      <td>0.463736</td>\n",
       "      <td>0.521070</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Training score  Validation score  Number of features\n",
       "Alpha Values                                                      \n",
       "0.0001              0.609071          0.636898                 8.0\n",
       "0.0010              0.609071          0.636899                 8.0\n",
       "0.0100              0.609071          0.636912                 8.0\n",
       "0.1000              0.609069          0.637034                 8.0\n",
       "1.0000              0.608852          0.638035                 8.0\n",
       "10.0000             0.602880          0.638874                 6.0\n",
       "100.0000            0.463736          0.521070                 5.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "    \n",
    "alpha = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "df = pd.DataFrame(columns = alpha, \n",
    "    index = ['Training score', 'Validation score', 'Number of features'])\n",
    "df.columns.name = 'Alpha Values'\n",
    "\n",
    "for a in alpha:\n",
    "    lasso = Lasso(alpha=a).fit(X_train, y_train) \n",
    "    df[a] = [lasso.score(X_train, y_train), lasso.score(X_test, y_test), \n",
    "             np.sum(lasso.coef_ != 0)]\n",
    "\n",
    "df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b606236",
   "metadata": {},
   "source": [
    "For the Ridge model I found no significant improvement in R2 with respect of different values of alpha. The only very slighly increase observed was for the validation score with higher values of alpha probably due to the regularization effect.\n",
    "\n",
    "This is a similar case for the Lasso model, although in this model I observed that the number of fetures droped from 8 to 5 for higher values of alpha along with the training and validation score. Suggesting that higher regularization is worsening and further underfitting the model.\n",
    "\n",
    "In conclusion the R2 scores are poor regardless of the model and alpha value used because a linear model is unable to capture the pattern within the concrete dataset and a more complex model is needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
